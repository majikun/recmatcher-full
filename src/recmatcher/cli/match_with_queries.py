from __future__ import annotations
import argparse, json
from pathlib import Path
import numpy as np
import cv2
import logging
import math
def _round_ms(x: float, ms: int = 3) -> int:
    # return integer milliseconds (ms=3) or decimilliseconds if ms=2, etc.
    if x is None:
        return -1
    return int(round(float(x) * (10 ** ms)))

def load_movie_meta_segs(segs_path: Path | None, store_root: Path | None = None):
    """Read movie meta segs and build lookup tables.
    If segs_path is provided, use it; else if store_root is provided, use store_root/movie/meta/segs.json.
    Returns (exact_map, by_scene).
    """
    if segs_path is not None:
        meta_path = Path(segs_path)
    elif store_root is not None:
        meta_path = store_root / "movie" / "meta" / "segs.json"
    else:
        meta_path = None

    exact_map = {}
    by_scene = {}
    if meta_path is None or not meta_path.exists():
        return exact_map, by_scene

    try:
        with open(meta_path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception:
        return exact_map, by_scene

    def _pick(d, keys, default=None, cast=None):
        for k in keys:
            if k in d and d[k] not in (None, ""):
                try:
                    return cast(d[k]) if cast else d[k]
                except Exception:
                    continue
        return default

    def _round_ms(x: float, ms: int = 3) -> int:
        if x is None:
            return -1
        return int(round(float(x) * (10 ** ms)))

    for row in (data or []):
        seg_id = _pick(row, ["seg_id", "id", "seg_idx", "segment_id"], default=None, cast=int)
        scene_seg_idx = _pick(row, ["scene_seg_idx", "seg_idx", "scene_seg_index"], default=None, cast=int)
        t0 = _pick(row, ["start", "t0", "ts", "begin"], default=0.0, cast=float)
        t1 = _pick(row, ["end", "t1", "te", "finish"], default=0.0, cast=float)
        scene_id = _pick(row, ["scene_id", "scene", "scene_idx"], default=None, cast=int)
        rec = {
            "seg_id": seg_id,
            "scene_seg_idx": scene_seg_idx,
            "start": float(t0 or 0.0),
            "end": float(t1 or 0.0),
            "scene_id": scene_id,
        }
        key = (_round_ms(t0), _round_ms(t1), scene_id)
        exact_map[key] = rec
        by_scene.setdefault(scene_id, []).append(rec)

    for sid in list(by_scene.keys()):
        by_scene[sid].sort(key=lambda r: r.get("start", 0.0))
    return exact_map, by_scene


def attach_seg_ids_from_meta(item: dict, exact_map: dict, by_scene: dict, tol_sec: float = 0.03) -> dict:
    """Fill seg_id / scene_seg_idx for a movie candidate item using movie meta segs.
    If either field is missing/None, try to backfill from (start,end,scene_id) match.
    Returns the mutated item.
    """
    need_seg_id = item.get("seg_id") is None
    need_scene_seg_idx = item.get("scene_seg_idx") is None
    if not (need_seg_id or need_scene_seg_idx):
        return item
    s = float(item.get("start", 0.0))
    e = float(item.get("end", 0.0))
    sid = item.get("scene_id")
    # exact match by rounded milliseconds
    key = (_round_ms(s), _round_ms(e), sid)
    rec = exact_map.get(key)
    if rec is None:
        # fuzzy within tol
        tol = float(tol_sec)
        bucket = by_scene.get(sid, [])
        best = None
        best_err = 1e9
        for r in bucket:
            err = max(abs(r["start"] - s), abs(r["end"] - e))
            if err <= tol and err < best_err:
                best = r
                best_err = err
        rec = best
    if rec:
        # Only overwrite missing (None) fields
        if need_seg_id and rec.get("seg_id") is not None:
            try:
                item["seg_id"] = int(rec.get("seg_id"))
            except Exception:
                item["seg_id"] = rec.get("seg_id")
        if need_scene_seg_idx and rec.get("scene_seg_idx") is not None:
            try:
                item["scene_seg_idx"] = int(rec.get("scene_seg_idx"))
            except Exception:
                item["scene_seg_idx"] = rec.get("scene_seg_idx")
    return item
def _read_clip_frames(path: Path, n: int = 24) -> np.ndarray:
    cap = cv2.VideoCapture(str(path))
    if not cap.isOpened():
        return np.zeros((0,), dtype=np.float32)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    idxs = np.linspace(0, max(0, frame_count-1), num=max(1, n), dtype=int)
    frames = []
    for i in idxs:
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(i))
        ok, f = cap.read()
        if not ok:
            continue
        f = cv2.cvtColor(f, cv2.COLOR_BGR2RGB)
        frames.append(f)
    cap.release()
    if not frames:
        return np.zeros((0,), dtype=np.float32)
    # stack to [T,H,W,3]
    return np.stack(frames, axis=0)

from ..matcher.query_io import load_queries
from ..matcher.stage1_retriever import Stage1Retriever
from ..matcher.stage2_reranker import Stage2Reranker
from ..utils.io import write_json
from ..utils.faiss_utils import IdMap
from ..types import CropVariant
import csv

# tag -> ç´¢å¼•å çš„é»˜è®¤æ˜ å°„ï¼ˆæŒ‰æˆ‘ä»¬ä¹‹å‰çš„æ–¹æ¡ˆï¼‰
VARIANT_MAP = {
    "tight": "centercrop",
    "context": "letterbox",
    "left": "h_left",
    "right": "h_right",
    "center": "h_center",  # è‹¥ç”µå½±ç«¯å»ºäº† center
}

# å˜ä½“æƒé‡ä¸èåˆæ¸©åº¦ï¼ˆè½»é‡æ ¡å‡†+æŠ•ç¥¨èåˆç”¨ï¼‰
VAR_WEIGHTS = {
    "centercrop": 1.00,
    "letterbox": 0.98,
    "h_left": 0.97,
    "h_center": 0.97,
    "h_right": 0.97,
}
VOTE_TAU = 0.06  # softmax æ¸©åº¦
MIRROR_PENALTY = 0.97  # é•œåƒå‘½ä¸­å°å¹…é™æƒ

def _compute_variant_calib(retriever, seg_bags, available_variants, sample_per_var: int = 128):
    """ä¼°è®¡æ¯ä¸ªå˜ä½“çš„ä¸€é˜¶æ®µåˆ†æ•°å°ºåº¦ï¼ˆä¸­ä½æ•°ä¸IQRï¼‰ï¼Œç”¨äºè·¨å˜ä½“æ ¡å‡†ã€‚
    è¿”å› {variant(str): (median, iqr)}ï¼Œè‹¥æ— æ ·æœ¬åˆ™ç»™å‡ºç¨³å¥é»˜è®¤å€¼ã€‚
    """
    import numpy as _np
    calib = {}
    by_var_vecs = {v: [] for v in available_variants}
    # ä» seg_bags é‡ŒæŠ½å–æ¯ä¸ªå˜ä½“çš„è‹¥å¹²æŸ¥è¯¢å‘é‡ï¼ˆåªå–å‰è‹¥å¹²ä¸ªï¼Œè¶³å¤Ÿä¼°è®¡å°ºåº¦ï¼‰
    for _sid, bag in seg_bags.items():
        for var, vec_items in bag.items():
            if var not in by_var_vecs:
                continue
            for it in vec_items:
                by_var_vecs[var].append(it["vec"])  # it æ˜¯ {"vec": ..., "mirrored": bool}
                if len(by_var_vecs[var]) >= sample_per_var:
                    break
    for var, arr in by_var_vecs.items():
        if not arr:
            calib[var] = (0.0, 0.06)  # ç¼ºçœå°ºåº¦
            continue
        X = _np.stack(arr).astype(_np.float32)
        try:
            D, I, _idm = retriever._search_variant(var, X)
            if D.size == 0:
                calib[var] = (0.0, 0.06)
                continue
            top1 = D[:, 0]
            med = float(_np.median(top1))
            q25, q75 = _np.percentile(top1, [25, 75])
            iqr = float(max(q75 - q25, 1e-3))
            calib[var] = (med, iqr)
        except Exception:
            calib[var] = (0.0, 0.06)
    return calib

def load_indices(store_root: Path):
    """
    åœ¨ store_root ä¸‹åŒæ—¶æœï¼š
      - movie/index/<variant>.faiss
      - movie/emb/<variant>_id_map.csv
    äºŒè€…éƒ½å­˜åœ¨æ‰çº³å…¥ã€‚
    é¢å¤–è¿”å› `id_rows`: {variant(str): List[dict]}ï¼Œä¾¿äºæŒ‰è¡Œå·å–å…ƒæ•°æ®ã€‚
    """
    index_dir = store_root / "movie" / "index"
    idmap_dir = store_root / "movie" / "emb"

    index_paths = {}
    id_maps = {}
    id_rows = {}

    variants = [
        CropVariant.LETTERBOX,
        CropVariant.CENTERCROP,
        CropVariant.H_LEFT,
        CropVariant.H_CENTER,
        CropVariant.H_RIGHT,
    ]

    for var in variants:
        faiss_path = index_dir / f"{var.value}.faiss"
        idmap_path = idmap_dir / f"{var.value}_id_map.csv"
        if faiss_path.exists() and idmap_path.exists():
            index_paths[var] = str(faiss_path)
            # åŸæœ‰ IdMapï¼ˆè‹¥åˆ«å¤„éœ€è¦ï¼‰
            id_maps[var] = IdMap.from_csv(idmap_path)
            # è¯»åŸå§‹è¡Œï¼Œåç»­æˆ‘ä»¬æŒ‰è¡Œå·æ‹¿æ—¶é—´/sceneç­‰
            rows = []
            with open(idmap_path, "r", encoding="utf-8") as f:
                reader = csv.DictReader(f)
                # Debug columns once per variant
                try:
                    print(f"[idmap] {var.value} columns:", reader.fieldnames)
                except Exception:
                    pass

                def _pick_num(d, keys, cast=float, default=None):
                    for k in keys:
                        if k in d and d[k] not in (None, ""):
                            try:
                                return cast(d[k])
                            except Exception:
                                continue
                    return default

                def _pick_float(d, keys, default=0.0):
                    return _pick_num(d, keys, cast=float, default=default)

                for row in reader:
                    seg_id = _pick_num(row, [
                        "seg_id", "segment_id", "orig_seg_id", "seg_idx", "idx", "id"
                    ], cast=int, default=None)

                    scene_seg_idx = _pick_num(row, [
                        "scene_seg_idx", "seg_idx", "scene_seg_index"
                    ], cast=int, default=None)

                    start_v = _pick_float(row, [
                        "start", "t0", "ts", "begin", "s"
                    ], default=0.0)

                    end_v = _pick_float(row, [
                        "end", "t1", "te", "finish", "e"
                    ], default=0.0)

                    scene_id = _pick_num(row, [
                        "scene_id", "scene", "scene_idx", "sceneindex"
                    ], cast=int, default=None)

                    faiss_id = _pick_num(row, ["faiss_id", "fid", "index"], cast=int, default=None)
                    movie_id = row.get("movie_id", None)
                    shot_id = _pick_num(row, ["shot_id", "shot", "shot_idx"], cast=int, default=None)

                    rows.append({
                        "faiss_id": faiss_id,
                        "movie_id": movie_id,
                        "shot_id": shot_id,
                        "seg_id": seg_id,
                        "scene_seg_idx": scene_seg_idx,
                        "start": start_v,
                        "end": end_v,
                        "scene_id": scene_id,
                    })
            id_rows[var.value] = rows

    print("[indices] found:", {k.value if hasattr(k, "value") else k for k in index_paths.keys()})
    return index_paths, id_maps, id_rows

def _temporal_nms(items, win_sec: float = 3.0):
    """Greedy temporal NMS on already-materialized dict items with 'start','end','score'.
    Keeps highest-score item per overlapping window of +/- win_sec around 'start'.
    """
    if not items:
        return items
    items = sorted(items, key=lambda x: x.get("start", 0.0))
    kept = []
    i = 0
    while i < len(items):
        s0 = items[i]["start"]
        # collect a window
        bucket = []
        j = i
        while j < len(items) and abs(items[j]["start"] - s0) <= win_sec:
            bucket.append(items[j])
            j += 1
        # pick max score in bucket
        best = max(bucket, key=lambda x: x.get("score", 0.0))
        kept.append(best)
        i = j
    return kept

def main():
    ap = argparse.ArgumentParser("recmatcher-match-from-queries")
    ap.add_argument("--queries", required=True, help="encode_clip äº§å‡ºç›®å½•ï¼ˆåŒ…å« queries/ å’Œ meta/ï¼‰")
    ap.add_argument("--clip_segs", required=True, help="åŒ encode é˜¶æ®µçš„åˆ†æ®µ JSONï¼ˆç”¨äºè¾“å‡ºå¯¹é½ï¼‰")
    ap.add_argument("--store", required=True, help="ç”µå½±ç´¢å¼•æ ¹ç›®å½•ï¼ˆå« movie/index/*.faissï¼‰")
    ap.add_argument("--out", required=True, help="è¾“å‡º match.json")
    ap.add_argument("--topk", type=int, default=20)
    ap.add_argument("--movie", required=True)
    ap.add_argument("--movie_segs", required=False, help="ç”µå½±åŸç‰‡åˆ†æ®µ JSONï¼ˆsegs.jsonï¼‰è·¯å¾„ï¼›ç”¨äºæŒ‰ (t0,t1,scene_id) åæŸ¥ seg_id/scene_seg_idx")
    ap.add_argument("--skip_movie", action="store_true", help="äºŒé˜¶æ®µé‡æ’æ—¶è·³è¿‡å–ç”µå½±åŸç‰‡å¸§")
    ap.add_argument("--clip", required=False, help="åŸçŸ­ç‰‡è·¯å¾„ï¼ˆç”¨äºäºŒé˜¶æ®µå‚è€ƒå¸§ï¼‰ï¼Œæ¨èæä¾›")
    ap.add_argument("--no_norm", action="store_true", help="ç¦ç”¨å¯¹æŸ¥è¯¢å‘é‡çš„L2å½’ä¸€åŒ–ï¼ˆé»˜è®¤ä¼šå½’ä¸€åŒ–ï¼‰")
    ap.add_argument("--nms_sec", type=float, default=0.0, help="å¯¹è¾“å‡ºåšç®€å•æ—¶é—´NMSçš„çª—å£ç§’æ•°(>0ç”Ÿæ•ˆ)")
    ap.add_argument("--debug_probe", type=int, default=0, help="è°ƒè¯•ï¼šåªå–å‰Næ¡æŸ¥è¯¢åšæ¢é’ˆå¹¶æ‰“å°æ¯ä¸ªvariantçš„top1å¾—åˆ†(0=å…³é—­)")
    ap.add_argument("--debug_dump_norms", action="store_true", help="è°ƒè¯•ï¼šæ‰“å°æŸ¥è¯¢å‘é‡çš„èŒƒæ•°ç»Ÿè®¡")
    ap.add_argument("--skip_rerank", action="store_true", help="å®Œå…¨è·³è¿‡äºŒé˜¶æ®µé‡æ’ï¼ˆä»…è¾“å‡ºä¸€é˜¶æ®µå¾—åˆ†ä¸å€™é€‰ï¼‰")
    ap.add_argument("--score_source", choices=["vp", "rerank", "max", "both"], default="vp",
                    help="é€‰æ‹©è¾“å‡ºçš„scoreæ¥æºï¼švp=ä¸€é˜¶æ®µç›¸ä¼¼åº¦ï¼›rerank=äºŒé˜¶æ®µåˆ†ï¼›max=ä¸¤è€…å–æœ€å¤§ï¼›both=åŒæ—¶å†™å…¥ä¸¤ä¸ªåˆ†å¹¶ä»¥vpä½œä¸ºscore")
    args = ap.parse_args()

    logging.basicConfig(level=logging.INFO)

    with open(args.clip_segs, "r", encoding="utf-8") as f:
        clip_segs = json.load(f)
    # æœŸæœ› clip_segs æ˜¯ listï¼Œæ¯é¡¹è‡³å°‘æœ‰ seg_id/start/end/scene_id/scene_seg_idx

    qdir = Path(args.queries)
    qlist = load_queries(qdir)
    
    index_paths, id_maps, id_rows = load_indices(Path(args.store))
    segs_path = Path(args.movie_segs) if getattr(args, "movie_segs", None) else None
    movie_exact, movie_by_scene = load_movie_meta_segs(segs_path, Path(args.store))
    retr = Stage1Retriever(index_paths=index_paths, id_maps=id_maps, topk=int(args.topk))

    # å–å¾—å¯ç”¨ç´¢å¼•çš„å˜ä½“åé›†åˆï¼ˆç»Ÿä¸€æˆå­—ç¬¦ä¸²ï¼Œå¦‚ 'letterbox'ï¼‰
    if hasattr(retr, "_indices"):
        keys = list(retr._indices.keys())
    elif hasattr(retr, "indices"):
        keys = list(retr.indices.keys())
    else:
        keys = []
    available_variants = { (k.value if hasattr(k, "value") else str(k)) for k in keys }
    print("[stage1] available variants:", sorted(available_variants))

    # æŠŠ tag æ˜ å°„æˆ retriever èƒ½è¯†åˆ«çš„ variantï¼ˆå’Œ store çš„ç´¢å¼•åä¸€è‡´ï¼‰ï¼Œå¹¶æŠŠ vecs[N,D] å±•å¼€ä¸ºé€æ¡ vec[D]
    qlist_mapped = []  # flat list: [{'variant': ..., 'tag': ..., 'mirrored': ..., 'vec': np.ndarray[D]}, ...]
    for q in qlist:
        tag = q["tag"]
        var = VARIANT_MAP.get(tag)
        if var is None or var not in available_variants:
            continue
        vecs = q["vecs"]
        if vecs is None:
            continue
        if vecs.ndim == 1:
            vecs = vecs[None, :]
        if vecs.shape[0] == 0:
            continue
        for i in range(vecs.shape[0]):
            v = vecs[i].astype(np.float32, copy=False)
            if not args.no_norm:
                nrm = float(np.linalg.norm(v))
                if nrm > 1e-6:
                    v = v / nrm
            qlist_mapped.append({
                "variant": var,
                "tag": tag,
                "mirrored": bool(q.get("mirrored", False)),
                "vec": v,
            })

    if args.debug_dump_norms:
        norms = []
        for q in qlist_mapped:
            v = q["vec"]
            norms.append(float(np.linalg.norm(v)))
        if norms:
            norms = np.array(norms, dtype=np.float32)
            print(f"[debug] query norms: min={norms.min():.4f} med={np.median(norms):.4f} max={norms.max():.4f}")
        else:
            print("[debug] query norms: EMPTY")

    if not qlist_mapped:
        raise SystemExit("No valid query vectors after mapping; check your --queries directory and VARIANT_MAP/indices alignment.")

    # å°†æ‰å¹³çš„æŸ¥è¯¢å‘é‡æŒ‰ seg_id èšåˆï¼š{ seg_id: { variant: [vec, ...] } }
    # å‡è®¾æ¯ä¸ª tag çš„ vecs æŒ‰ clip_segs é¡ºåºæ’åˆ—
    seg_bags = {}
    num_segs = len(clip_segs) if isinstance(clip_segs, list) else 0
    # å…ˆåˆå§‹åŒ– seg å®¹å™¨
    for s in clip_segs:
        seg_bags[s.get("seg_id")] = {}
    # é‡æ–°ä»åŸå§‹ qlistï¼ˆå¸¦ vecs æ‰¹é‡ï¼‰åšä¸€æ¬¡èšåˆï¼Œé¿å…ä¸¢å¤±æ®µä½æ¬¡åº
    for q in qdir.iterdir() if False else qlist:  # å ä½é˜²é™æ€æ£€æŸ¥ï¼›çœŸå®ç”¨ qlist
        tag = q["tag"]
        var = VARIANT_MAP.get(tag)
        if var is None:
            continue
        vecs = q["vecs"]
        if vecs is None:
            continue
        # ä¿éšœ 2D å½¢çŠ¶ [N,D]
        if vecs.ndim == 1:
            vecs = vecs[None, :]
        n = vecs.shape[0]
        # ä¸ clip_segs å¯¹é½ï¼Œå– min é˜²æ­¢è¶Šç•Œ
        L = min(n, num_segs)
        for i in range(L):
            sid = clip_segs[i].get("seg_id")
            v = vecs[i].astype(np.float32, copy=False)
            if not args.no_norm:
                nrm = float(np.linalg.norm(v))
                if nrm > 1e-6:
                    v = v / nrm
            seg_bags[sid].setdefault(var, []).append({"vec": v, "mirrored": bool(q.get("mirrored", False))})

    def _probe_variants(retriever, qitems, topk=5):
        """Return dict: {variant: top1_list} for the first few queries per variant."""
        by_var = {}
        for qi in qitems:
            by_var.setdefault(qi["variant"], []).append(qi)
        report = {}
        for var, items in by_var.items():
            D, I, idm = retriever._search_variant(var, np.stack([x["vec"] for x in items]).astype(np.float32))
            # D shape [N, topk]
            top1 = D[:, 0].tolist() if D.size else []
            report[var] = top1
        return report

    if args.debug_probe and args.debug_probe > 0:
        N = int(args.debug_probe)
        sample = qlist_mapped[:N]
        rep = _probe_variants(retr, sample, topk=min(args.topk, 10))
        print("[probe] per-variant top1 stats on first", N, "queries:")
        for var, arr in rep.items():
            if arr:
                a = np.array(arr, dtype=np.float32)
                print(f"  - {var:11s}: n={len(arr):4d} min={a.min():.3f} med={np.median(a):.3f} max={a.max():.3f}")
            else:
                print(f"  - {var:11s}: n=0")

    def _row_start_end(m):
        # m å·²ç»æ ‡å‡†åŒ–äº† start/endï¼Œä½†ä¸ºäº†ä¿é™©å†å…œåº•ä¸€ä¸‹
        s = m.get("start")
        e = m.get("end")
        if s is None:
            s = m.get("t0", 0.0)
        if e is None:
            e = m.get("t1", 0.0)
        return float(s or 0.0), float(e or 0.0)

    # åŸºäºå½“å‰æŸ¥è¯¢åŒ…ä¼°è®¡å„å˜ä½“åˆ†æ•°å°ºåº¦ï¼Œç”¨äºè·¨å˜ä½“æ ¡å‡†
    calib_tbl = _compute_variant_calib(retr, seg_bags, available_variants)

    def retrieve_one_seg(seg_id, bag, topk):
        """bag: {variant(str): [ {"vec": ndarray, "mirrored": bool}, ... ]}
        å¤šå˜ä½“èåˆç­–ç•¥ï¼š
          1) å¯¹æ¯ä¸ªå˜ä½“çš„åˆ†æ•°åšç¨³å¥æ ¡å‡†ï¼ˆå‡ä¸­ä½æ•°/é™¤IQRï¼‰ã€‚
          2) å°†æ ¡å‡†åçš„åˆ†æ•°è¿›å…¥ softmax æŠ•ç¥¨å¹¶ä¹˜ä»¥å˜ä½“æƒé‡ä¸é•œåƒæƒ©ç½šï¼Œ
             å¯¹åŒä¸€ (start,end,scene) ç´¯åŠ ç¥¨æ•°ï¼›
          3) åŒæ—¶è®°å½•è¯¥ key ä¸‹çš„æœ€å¤§åŸå§‹åˆ†æ•°ï¼ˆä¾¿äºä¿æŒåˆ†æ•°å°ºåº¦è¾“å‡ºï¼‰ã€‚
        è¿”å› list[dict]ï¼Œæ¯ä¸ª dict é¢å¤–å¸¦ `vote` å­—æ®µä½œä¸ºèåˆå¾—åˆ†ã€‚
        """
        fuse_vote = {}   # key -> ç´¯è®¡ç¥¨æ•°
        fuse_meta = {}   # key -> ä»£è¡¨å…ƒæ•°æ®ï¼ˆæ¥è‡ªæœ€å¤§åŸå§‹åˆ†æ•°çš„é‚£ä¸€æ¡ï¼‰
        fuse_best = {}   # key -> æœ€å¤§åŸå§‹åˆ†æ•°

        for var, vec_list in bag.items():
            if var not in available_variants:
                continue
            if not vec_list:
                continue
            X = np.stack([it["vec"] for it in vec_list]).astype(np.float32)
            mir_flags = [bool(it.get("mirrored", False)) for it in vec_list]
            try:
                D, I, _idm = retr._search_variant(var, X)
            except Exception:
                continue
            rows = id_rows.get(var, [])
            mu, iqr = calib_tbl.get(var, (0.0, 0.06))
            w_var = VAR_WEIGHTS.get(var, 0.97)
            for r in range(I.shape[0]):
                mir_w = (MIRROR_PENALTY if mir_flags[r] else 1.0)
                for k in range(min(I.shape[1], topk)):
                    j = int(I[r, k])
                    if j < 0 or j >= len(rows):
                        continue
                    m = rows[j]
                    ss, ee = _row_start_end(m)
                    key = (ss, ee, m.get("scene_id"))
                    sc = float(D[r, k])
                    # æ ¡å‡†åˆ°è¿‘ä¼¼åŒå°ºåº¦ååš soft-vote
                    z = (sc - mu) / max(iqr, 1e-3)
                    vote = math.exp(z / VOTE_TAU) * w_var * mir_w
                    fuse_vote[key] = fuse_vote.get(key, 0.0) + vote
                    # è®°å½•æœ€å¤§åŸå§‹åˆ†æ•°å¯¹åº”çš„å…ƒä¿¡æ¯
                    if key not in fuse_best or sc > fuse_best[key]:
                        fuse_best[key] = sc
                        fuse_meta[key] = m

        # ç»„è£…å€™é€‰ï¼Œå¹¶æŒ‰ vote ä¼˜å…ˆã€åŸå§‹åˆ†æ•°æ¬¡ä¹‹æ’åº
        items = []
        for key, vt in fuse_vote.items():
            m = fuse_meta.get(key)
            if not m:
                continue
            ss, ee = _row_start_end(m)
            cand = {
                "seg_id": m.get("seg_id"),
                "scene_seg_idx": m.get("scene_seg_idx"),
                "start": ss,
                "end": ee,
                "scene_id": m.get("scene_id"),
                "score": float(fuse_best.get(key, 0.0)),  # ä¿æŒåŸåˆ†æ•°å°ºåº¦ä¾¿äºè§‚æµ‹
                "vote": float(vt),                        # ç”¨äºæ’åºçš„èåˆå¾—åˆ†
                "faiss_id": m.get("faiss_id"),
                "movie_id": m.get("movie_id"),
                "shot_id": m.get("shot_id"),
            }
            cand = attach_seg_ids_from_meta(cand, movie_exact, movie_by_scene)
            items.append(cand)

        items.sort(key=lambda x: (-x.get("vote", x.get("score", 0.0)), -x.get("score", 0.0)))
        return items[:topk]

    # === Per-seg æ£€ç´¢ä¸èåˆï¼Œè¾“å‡ºåˆ†æ®µç»“æœ ===
    results = []
    for s in clip_segs:
        sid = s.get("seg_id")
        bag = seg_bags.get(sid, {})
        if not bag:
            top_items = []
        else:
            top_items = retrieve_one_seg(sid, bag, topk=int(args.topk))
            if args.nms_sec and args.nms_sec > 0:
                top_items = _temporal_nms(top_items, win_sec=float(args.nms_sec))
                
        # ğŸ‘‰ å…ˆæŒ‰èåˆæŠ•ç¥¨(vote)é™åºï¼Œå†æŒ‰åŸå§‹åˆ†æ•°ä¸æ—¶é—´ç¨³å®šæ’åº
        top_items.sort(key=lambda x: (-float(x.get("vote", x.get("score", 0.0))),
                                      -float(x.get("score", 0.0)),
                                      float(x.get("start", 0.0)),
                                      float(x.get("end", 0.0))))
        
        # Wrap matched_orig_seg and top_matches properly
        def wrap_items(items):
            wrapped = []
            for item in items:
                wrapped.append({
                    "seg_id": item.get("seg_id"),
                    "scene_seg_idx": item.get("scene_seg_idx"),
                    "start": item.get("start"),
                    "end": item.get("end"),
                    "scene_id": item.get("scene_id"),
                    "score": item.get("score"),
                    "faiss_id": item.get("faiss_id"),
                    "movie_id": item.get("movie_id"),
                    "shot_id": item.get("shot_id"),
                })
            return wrapped
        wrapped_top_items = wrap_items(top_items)[:10]
        matched_orig_seg = wrapped_top_items[0] if wrapped_top_items else None
        out = {
            "seg_id": sid,
            "scene_seg_idx": s.get("scene_seg_idx"),
            "start": float(s.get("start", 0.0)),
            "end": float(s.get("end", 0.0)),
            "scene_id": s.get("scene_id"),
            "matched_orig_seg": matched_orig_seg,
            "top_matches": wrapped_top_items,
        }
        results.append(out)

    # ç»Ÿè®¡ä¸€ä¸‹æ•´ä½“åˆ†æ•°åˆ†å¸ƒï¼ˆåŸºäº matched_orig_segï¼‰
    scores = [x["matched_orig_seg"]["score"] for x in results if x.get("matched_orig_seg")]
    if scores:
        scores = np.array(scores, dtype=np.float32)
        print(f"[summary] matched top1: min={scores.min():.3f} med={np.median(scores):.3f} max={scores.max():.3f} (n={len(scores)})")

    Path(args.out).parent.mkdir(parents=True, exist_ok=True)
    write_json(Path(args.out), results)
    return


if __name__ == "__main__":
    main()